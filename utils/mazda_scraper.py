import pandas as pd
import time
import traceback
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service as ChromiumService
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType

# âœ… WebDriverç”Ÿæˆé–¢æ•°ï¼ˆãƒãƒ„ãƒ€å°‚ç”¨ï¼‰
def generate_driver():
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920x1080")
    options.add_argument("--disable-features=VizDisplayCompositor")
    return webdriver.Chrome(
        service=ChromiumService(
            ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install()
        ),
        options=options
    )

# âœ… æœ¬æ–‡æŠ½å‡ºï¼ˆpã‚¿ã‚°ã¨tableå¯¾å¿œï¼‰
def extract_content_text(content_div):
    texts = []
    for element in content_div.contents:
        if not hasattr(element, "name"):
            continue
        if element.name == "p":
            paragraph = element.get_text(" ", strip=True)
            if paragraph:
                texts.append(paragraph)
        elif element.name == "table":
            for row in element.find_all("tr"):
                cells = row.find_all(["th", "td"])
                row_text = "ï½œ".join(
                    cell.get_text(" ", strip=True) for cell in cells
                )
                texts.append(row_text)
    return "\n".join(texts)

# âœ… ãƒãƒ„ãƒ€ãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡æŠ½å‡ºä»˜ãé–¢æ•°
def scrape_articles_mazda(year, start_date, end_date):
    print(f"ğŸš— scrape_articles_mazda é–‹å§‹: {year}å¹´ï¼ˆ{start_date.date()}ã€œ{end_date.date()}ï¼‰")
    driver = generate_driver()
    data = []

    url = f"https://www.mazda.co.jp/news_list/{year}/"
    print(f"ğŸŒ ã‚¢ã‚¯ã‚»ã‚¹URL: {url}")
    driver.get(url)
    time.sleep(2)

    soup = BeautifulSoup(driver.page_source, "html.parser")
    box = soup.find("div", class_="Notification__list__box2")

    if not box:
        print("âš ï¸ ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return pd.DataFrame()

    dls = box.find_all("dl")
    for dl in dls:
        try:
            date = dl.find("dt").get_text(strip=True)
            date_obj = pd.to_datetime(date, format="%Yå¹´%mæœˆ%dæ—¥", errors="coerce")
            if pd.isna(date_obj):
                continue

            # ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆæ–°ã—ã„é †ï¼‰
            if date_obj < end_date:
                print(f"ğŸ›‘ {date} ã¯ç¯„å›²ã‚ˆã‚Šå¤ã„ãŸã‚æ‰“ã¡åˆ‡ã‚Š")
                break
            elif date_obj > start_date:
                print(f"â© {date} ã¯ç¯„å›²ã‚ˆã‚Šæ–°ã—ã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                continue

            link_tag = dl.find("dd").find("a")
            title = link_tag.get_text(strip=True)
            href = link_tag["href"]
            full_link = f"https://www.mazda.co.jp{href}"

            # æœ¬æ–‡å–å¾—
            driver.execute_script("window.open('');")
            driver.switch_to.window(driver.window_handles[1])
            driver.get(full_link)

            WebDriverWait(driver, 10).until(
                EC.visibility_of_element_located((By.CLASS_NAME, "detail-content"))
            )
            detail_soup = BeautifulSoup(driver.page_source, "html.parser")
            content_div = detail_soup.select_one("div.detail-content")

            if content_div:
                body_text = extract_content_text(content_div)
            else:
                body_text = "æœ¬æ–‡æŠ½å‡ºä¸å¯"

            data.append({
                "æ—¥ä»˜": date,
                "è¦‹å‡ºã—": title,
                "æœ¬æ–‡": body_text.strip(),
                "ãƒªãƒ³ã‚¯": full_link
            })

            print(f"âœ… æŠ½å‡ºæˆåŠŸ: {title}")
            driver.close()
            driver.switch_to.window(driver.window_handles[0])
            time.sleep(1)

        except Exception as e:
            print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            try:
                driver.switch_to.window(driver.window_handles[0])
            except:
                pass
            continue

    driver.quit()
    return pd.DataFrame(data)

